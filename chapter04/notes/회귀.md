## 회귀(Regression)

### 회귀의 정의
- 독립변수로 종속변수의 값을 설명/예측한다
- 독립변수에 대한 선형 함수로 종속변수를 설명할 수 있다면 선형회귀(Linear Regression)라고 한다
- 사용하는 독립변수의 개수에 따라서 단순선형회귀(Simple Linear Regression), 다중선형회귀(Multiple Linear Regression)로 구분한다

### 단순선형회귀
- 독립변수 한 개로 종속 변수를 설명하는 선형회귀식을 구한다
- 선형회귀식으로 추정한 값과 실제 관측값의 차이를 최소로 만드는 모수를 추정한다
  - 차이 제곱 합에 대한 식을 미분하여서 최소로 만드는 모수 추정량 계산
<p align="center">
    <img width="300" height="" src="../images/equation_simple-regression.png"/>
</p>

- 제대로 만들어진 선형회귀식은 오차와 잔차가 비슷할 것이다
  - 오차: 관찰할 수 없는 모수
  - 잔차: 관측값에서 추정값을 뺀 값
  - 오차가 정규분포를 따른다는 가정하에 잔차제곱합으로 모수(오차)의 분산을 추정
<p align="center">
    <img width="150" height="" src="../images/equation_error.png"/>
</p>

### 다중선형회귀
- 독립변수 p개로 종속 변수를 설명하는 선형회귀식을 구한다
- 일반적으로 행렬로 표기한다.
<p align="center">
    <img width="300" height="" src="../images/equation_multiple-regression.png"/>
</p>

- 다중선형회귀에서는 다중공산성에 유의한다.
  - 다중공산성: 독립변수끼리 선형관계가 있어서 선형회귀식에 신뢰도를 떨어뜨린다
  - 다중공산성은 분산팽창계수(Variance Inflation Factor, VIF)이 큰 경우(5~10) 다중공산성이 있다고 가정한다
<p align="center">
    <img width="300" height="" src="../images/equation_vif.png"/>
</p>


### 선형회귀모형의 평가
**1. 결정계수와 수정된 결정계수**
- 결정계수: 자료가 가지는 전체적인 변동에 대해서 회귀식이 설명한느 변동의 비율. 
- 결정계수가 1에 가까울 수록 선형회귀식이 관측값이 실제값과 유사한 것을 의미한다
- 결정게수는 사용하는 독립변수의 개수가 늘어날수록 높은 값을 가질 확률이 커지므로 데이터의 개수와 사용하는 독립변수의 개수를 인자로 패널티를 부과하는 수정된 결정계수도 활용한다

<p align="center">
    <img width="300" height="" src="../images/equation_r.png"/>
</p>

**2. MSE와 MAE**
- MSE: 관측치와 추정치 사이에 오차제곱의 합. 자료의 스케일에 따라서 값이 달라질 수 있다.
- MAE: MSE는 오차가 클수록 패널티가 크기 때문에 일르 조정하는 MAE 사용.

<p align="center">
    <img width="200" height="" src="../images/equation_mse-mae.png"/>
</p>

### 선형회귀모형의 진단
- 선형회귀모형은 오차에 대한 가정이 필요하다
  1. 독립성: 오차는 서로 관련이 없다
  2. 등분산성: 자료의 퍼짐 정도는 독립변수의 수준과 관련이 없다
  3. 정규성: 자료들은 회귀모형을 기준으로 정규분포를 띈다.
- 오차를 대표하는 잔차를 산점도로 그려서 선형회귀모형을 진단한다.
  1. 산점도가 패턴이 없다 → 제대로된 선형회귀모형
  2. 산점도가 포물선이다 → 선형회귀모형에 이차항이 필요하다
  3. 산점도가 나팔모양이다 (앞/뒤로 갈수록 좁아지는 사다리꼴) → 등분산가정이 위배되었다
  4. 산점도가 직선모양이다 → 선형회귀모형에 새로운 독립변수가 필요하다 
- 이상치로 인해 선형회귀모형에 왜곡이 발생할 수 있으므로 분석가의 판단이 필요하다.

### 벌점화회귀
- 회귀식을 비롯한 모형 추정은 '비용함수를 최소화하는 모수'를 찾는 과정
  - 일반적으로 비용함수는 잔차들의 최소제곱합으로 구한다
- 과적합을 방지하기 위해 비용함수에 Regularization 항을 추가
  1. Ridge Regression (L2 Regularization)
  2. Lasso Regression (L1 Regularization)
  3. Elasticnet Regression = Ridge + Lasso

<p align="center">
    <img width="" height="" src="../images/equation_penalty.png"/>
</p>

- Regularization을 사용해서 모수(가중치)가 0에 가까운 작은 값으로 이끈다
  - 특히 Lasso Regression은 특정 모수(가중치)가 0이 될 수 있기 때문에 Feature Selection으로 사용할 수 있다

<p align="center">
    <img width="" height="" src="../images/figure_compare-l1-l2.png">
</p>

```
- 타원의 넓이가 가장 작은 선에서 모수(가중치, β)가 정해지는 것이 좋음
- Regularization이 추가됨에 따라서 원(L2) 또는 마름모(L1) 안에서 모수가 결정되어야한다
- 따라서 타원의 넓이가 점점 커지면서 원 또는 마름모와 닿을 때 모수(가중치, β)가 최종 모수이다
- 마름모(L1)인 경우 원(L2)인 경우와 다른게 한 쪽이 0이 될 가능성이 상대적으로 높다
    → Feature Selection
```

---

## Quiz
1. 다음 중 선형회귀에 대한 설명으로 틀린 것은?
  1. 독립변수와 종속변수의 관계를 선형인 함수로 가정할 수 있는 경우의 분석 방법이다. (O)
  2. 회귀분석에서 가장 먼저 선행되어야 할 부분은 시각적으로 자료들이 어떻게 산재되어 있으며, 어떤 관계를 지니고 있는지를 살펴보는 일이다. (O)
  3. 실제로 자료를 생성한 미지의 구조를 결정하는 상수들을 모수(parameter)라고 부른다. (O)
  4. 실제 관측치에서 평균추정값을 뺀 y-yhat을 r로 표기하며 잔차(residual)라고 부른다. (O)
  5. 다항선형회귀분석이란 의미 그대로 독립변수가 두 개 이상인 선형회귀모형을 이용한 회귀분석을 뜻한다. (X, 다항선형회귀분석 → 다중선형회귀분석) 
2. 다음 주 다중회귀에 대한 설명으로 맞는 것은?
   1. 특성이 다른 여러 개의 데이터(예를 들어 성별이나 자동차 색깔 등)에 대해 알맞은 모형을 각각 개발해야 한다. (X, 하나의 모델에 모수로 선형식을 만든다)
   2. 독립변수가 한 개인 모형을 단순선형회귀모형, 두 개인 모형을 쌍대선형회귀모형, 세 개 이상인 선형회귀모형을 다중선형회귀분석이라 한다. (X, 2개 이상이면 다중선형회귀분석)
   3. 더미변수를 이용하면 절편 이외에도 기울기도 다른 모형을 만들 수 있다. (O)
   4. 다중공선성은 전체적인 모형의 정확도나 적합성을 크게 변화시킨다. (X, 정확도나 적합성을 변화시키지 않지만 모수에 대한 신뢰를 떨어뜨린다)
   5. 독립변수들 간의 설명력 판별을 위해서 주로 분산설명계수를 이용한다. (X, 분산설명계수 → 분산팽창계수 VIF)
3. 회귀 모형 평가의 대표적인 기준과 걸명이 아닌 것은?
   1. 해석력: 해석이 용이한가 (O)
   2. 효율성: 모형이 단순한가 (O)
   3. 예측력: 잘 예측하는가 (O)
   4. 안정성: 자료가 변해도 결과가 크게 바뀌지 않는가 (O)
   5. 응집성: 같은 특성을 가진 데이터끼리 잘 뭉쳐져 있는가 (X, 군집화 평가 기준)
4. 다중 오차에 대한 가정으로 틀린 것은?
   1. 독립성: 오차들은 서로 관련이 없다
   2. 등분상성: 자료들의 퍼짐의 정도는 독립변수의 수준과 관련이 없다
   3. 중복성: 오창들이 서로 같은 방향으로 중복된다 (X)
   4. 정규성: 자료들은 회귀모형을 기준으로 정규분포 모양을 띤다.
5. 이상치를 판단하는데 있어 틀린 설명은?
   1. 이상치를 판단하려면 산점도를 그려 보면 도움이 된다 (O)
   2. 잘못되거나, 특수한 상황에서 기록된 데이터여서 다른 데이터와 양상이 다른 값을 이상치라 볼 수 있다. (O)
   3. 정규분포 가정하에서 발견하기 어려운 데이터가 발견되었다면 이는 이상치로 볼 수 있다. (O)
   4. 이상치는 의사결정나무와 선형회귀 같은 방법에서는 크게 제거하지 않아도 영향이 없다. (X, 모수가 달라진다)
6. 벌점화회귀에 대한 설명으로 틀린 것은?
   1. 벌점함수가 더해진 비용 함수를 최소화하는 모술르 찾는 회귀분석 방법을 lasso 회귀라고 부른다. (O)
   2. 예측력을 높이기 위한 방법 중, 모형의 복잡도를 증가시켜 나가면서 함수를 추정하는 것이 가능하다 (X, 예측력을 높이기 위해서는 모형의 복잡도를 낮추어야한다.)
   3. 복잡도를 증가시키는 만큼 설명력도 높아지기 때문에 벌점화 함수는 설명력을 높이는데 최대한의 목적을 둔다. (O)
   4. λ는 추정값의 수준을 결정한다는 의미에서 조절모수(control parameter) 또는 튜닝 모수(tuning parameter)라고 부른다 (O)
   5. 벌점함수를 이용하는 규제(regularization)는 기본적으로 추정치를 0근방으로 축소(shrinkage)하는 역할을 한다. (O)